{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW2: Fun with Image Gradients"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file we will explore the use of image gradients for edge detection.\n",
    "\n",
    "We will \n",
    "* use the Sobel operator and the Gaussian derivative for edge detection\n",
    "* explore the use of the fourier transform for edge detection\n",
    "* perform the Laplacian pyramid decomposition and reconstruction\n",
    "* corner detection using the Harris corner detector \n",
    "* and finally blob detection with the Gaussian pyramid\n",
    "\n",
    "we will use the following functions and other from OpenCV:\n",
    "`cv2.Sobel, cv2.GaussianBlur, cv2.pyrUp, cv2.pyrDown, cv2.magnitude`\n",
    "\n",
    "we will also use the following and other functions from numpy:\n",
    "`np.fft.fft2, np.fft.ifft2, np.fft.fftshift, np.fft.ifftshift, np.fft.fftshift, np.fft.ifftshift`\n",
    "\n",
    "we will also use the following and other functions from matplotlib:\n",
    "`plt.imshow, plt.subplot, plt.show, plt.title, plt.axis, plt.gray, plt.colorbar`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "import skimage.data\n",
    "import skimage.io\n",
    "import scipy.spatial\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load an image (grayscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = skimage.data.camera()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some helper functions for performing a Fourier Trasnform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a fourier transform as an image\n",
    "def show_ft(shift,subplt=111,title='FT Spectrum'):\n",
    "    magnitude_spectrum = 20*np.log(np.abs(shift.copy()))\n",
    "    if subplt != None:\n",
    "        plt.subplot(subplt)\n",
    "    plt.title(title)\n",
    "    plt.imshow(magnitude_spectrum,cmap='Spectral',interpolation='nearest')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "# 2D Fourier Transform\n",
    "# https://docs.scipy.org/doc/numpy/reference/generated/numpy.fft.fft2.html\n",
    "# https://docs.scipy.org/doc/numpy/reference/generated/numpy.fft.fftshift.html\n",
    "def ft(im,newsize=None):\n",
    "    dft = np.fft.fft2(np.float64(im),newsize)\n",
    "    return np.fft.fftshift(dft)\n",
    "\n",
    "# perform the 2D Fourier Transform and show the result\n",
    "def ft_and_show(im,subplt=111,newsize=None,title='FT Spectrum'):\n",
    "    shift = ft(im, newsize)\n",
    "    show_ft(shift, subplt, title)\n",
    "    return shift\n",
    "\n",
    "# Inverse 2D Fourier Transform\n",
    "# https://docs.scipy.org/doc/numpy/reference/generated/numpy.fft.ifftshift.html\n",
    "# https://docs.scipy.org/doc/numpy/reference/generated/numpy.fft.ifft2.html\n",
    "# https://docs.scipy.org/doc/numpy/reference/generated/numpy.abs.html\n",
    "def ift(shift):\n",
    "    f_ishift = np.fft.ifftshift(shift)\n",
    "    img_back = np.fft.ifft2(f_ishift)\n",
    "    return np.abs(img_back)\n",
    "\n",
    "# perform the inverse 2D Fourier Transform and show the result\n",
    "def ift_and_show(shift,subplt=111,title='Reconstructed Image'):\n",
    "    img_back = ift(shift.copy())\n",
    "    if subplt != None:\n",
    "        plt.subplot(subplt)\n",
    "    plt.title(title)\n",
    "    plt.imshow(img_back,cmap='gray',interpolation='nearest')\n",
    "    return img_back"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given an image we apply any convolution kernel arbitrarily by transforming both image and kernel to the frequency domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 17x17 Gaussian kernel\n",
    "gk = cv2.getGaussianKernel(17,2)\n",
    "\n",
    "# Show the blur operation done by FT\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(151),plt.imshow(im, cmap='gray'),plt.title('Input')\n",
    "imf = ft_and_show(im, 152, (im.shape[1],im.shape[1]), 'Image FT') # image in F domain\n",
    "ckf = ft_and_show(gk, 153, (im.shape[1],im.shape[1]), 'Blur kernel FT') # kernel in F domain\n",
    "imconvf = imf * ckf # multiplication in Freq domain = convolution in spatial domain\n",
    "show_ft(imconvf, 154)\n",
    "# show_ft(imconvf / ckf, 155)\n",
    "imconv = ift_and_show(imconvf, 155, 'Blurred image')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Here comes your part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deconvolve the image `imconv` given the (Gaussian) kernel that created it `gk`, and show the result. Use `ft` and `ift` functions from above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what we'd expect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "#TODO: your code, show the deconvolution process\n",
    "# make sure sizes match so we can multiple easily, e.g. by supplying (im.shape[0],im.shape[1]) to ft_and_show\n",
    "# get the FT of imconv, use 141 as the subplot number\n",
    "imf = ft_and_show(imconv, 141, (im.shape[0],im.shape[1]), 'Blurred image FT')\n",
    "# get the FT of gk, use 142 as the subplot number\n",
    "gkf = ft_and_show(gk, 142, (im.shape[0],im.shape[1]), 'Blur kernel FT')\n",
    "# in the frequency domain \"de-apply\" the kernel by dividing imf by it\n",
    "deconvft = imf / gkf\n",
    "# show the result of the division in the frequency domain (use 143 as the subplot number) using show_ft\n",
    "show_ft(deconvft, 143)\n",
    "\n",
    "# now reconstruct the blurred image from its FT\n",
    "# use ift_and_show to show the result, supply deconvft and 144 as the subplot number\n",
    "unblurred = ift_and_show(deconvft, 144, 'Deconvolved image')\n",
    "\n",
    "# plt.subplot(121),plt.imshow(imconv),plt.title('Blurred')\n",
    "# plt.subplot(122),plt.imshow(unblurred),plt.title('Deconvolved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply a high pass filter to the fft of the image by setting the low frequencies to zero\n",
    "# and then reconstruct the image from the filtered fft\n",
    "plt.figure(figsize=(20,10))\n",
    "imf = ft_and_show(im, 131, (im.shape[1],im.shape[1]), 'Image FT') # image in F domain\n",
    "mid_width = imf.shape[1]//2\n",
    "mid_height = imf.shape[0]//2\n",
    "#TODO: your code, set the low frequencies to zero\n",
    "# either by setting the values to zero (simple =0 assignment) or by multiplying by a mask\n",
    "# or painting a circle of zeros on the center of the image (cv2.circle)\n",
    "# e.g. imf[...] = ... goes here\n",
    "threshold = 50\n",
    "imf[mid_height-threshold:mid_height+threshold, mid_width-threshold:mid_width+threshold] = 0\n",
    "\n",
    "# using show_ft show the result of the high pass filter in the frequency domain (use 132 as the subplot number) \n",
    "show_ft(imf, 132)\n",
    "# using ift_and_show reconstruct the image from the filtered fft (use 133 as the subplot number)\n",
    "imconv = ift_and_show(imf, 133, 'High pass filtered image')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pyramid Blending\n",
    "\n",
    "We will now implement the Laplacian pyramid blending algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here's an image of an apple and an orange\n",
    "url = \"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fmedia.istockphoto.com%2Fphotos%2Fapple-and-orange-difference-picture-id637563258%3Fk%3D6%26m%3D637563258%26s%3D170667a%26w%3D0%26h%3DV3ZWrncLd8Fx8JdDODw0fCryk9-dimP9HS1wgwLsorI%3D&f=1&nofb=1&ipt=10e5cfd56eda60158ba3e0a3bc84a636c0fcda950b874a86ce42beeaf9866c73&ipo=images\"\n",
    "# load the image from the url and convert it to grayscale\n",
    "im = skimage.io.imread(url) / 255.0\n",
    "apple = im[60:316,246:]\n",
    "orange = im[63:319,5:261]\n",
    "# show the apple and the orange, and both fused together in the middle\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.subplot(131),plt.imshow(apple),plt.title('Apple ' + str(apple.shape) + ' ' + str(apple.dtype))\n",
    "plt.subplot(132),plt.imshow(orange),plt.title('Orange ' + str(orange.shape) + ' ' + str(orange.dtype))\n",
    "plt.subplot(133),plt.imshow(np.hstack((apple[:,:125],orange[:,125:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildLaplacianPyramid(G, levels=6):\n",
    "    #TODO: your code here\n",
    "    # Gaussian pyramid\n",
    "    # initialize the Gaussian pyramid with the original image, G\n",
    "    # and then build the Gaussian pyramid by repeatedly downsampling the image\n",
    "    gpA = [G]\n",
    "    for i in range(levels):\n",
    "        # Blur and downsample the image to get the next level of the pyramid\n",
    "        # using the cv2.pyrDown function\n",
    "        G = cv2.pyrDown(G)\n",
    "        # append the image to the pyramid\n",
    "        gpA.append(G)\n",
    "\n",
    "    # Laplacian pyramid\n",
    "    # initialize the Laplacian pyramid with the last (smallest) level of the Gaussian pyramid\n",
    "    # and then build the Laplacian pyramid by repeatedly upsampling the image and subtracting\n",
    "    lpA = [gpA[levels]] # keep smallest Gaussian at bottom\n",
    "    for i in range(levels,0,-1):\n",
    "        # get the Gaussian at this level from the Gaussian pyramid and upsample it using cv2.pyrUp\n",
    "        GE = cv2.pyrUp(gpA[i])\n",
    "\n",
    "        # subtract the upsampled Gaussian in this from the Gaussian one level up, e.g. gpA[i-1]\n",
    "        # to get (approximately) the Laplacian at this level\n",
    "        L = gpA[i-1] - GE\n",
    "\n",
    "        # append the result to the Laplacian pyramid\n",
    "        lpA.append(L)\n",
    "    \n",
    "    # return the Laplacian pyramid\n",
    "    return lpA\n",
    "\n",
    "applePyr = buildLaplacianPyramid(apple)\n",
    "orangePyr = buildLaplacianPyramid(orange)\n",
    "\n",
    "#TODO: your code here\n",
    "# combine applePyr + orangePyr to a new pyramid\n",
    "newPyr = [] # initialize the new pyramid\n",
    "for i in range(6):\n",
    "    # get half of the width of the image at this level using the shape of the image and the int() \n",
    "    # function to round down to the nearest integer value (//2) \n",
    "    half_width_at_scale = int(applePyr[i].shape[1] // 2)\n",
    "\n",
    "    # combine the two images at this level by stacking them side by side (np.hstack)\n",
    "    # and append to the new pyramid list (newPyr.append)\n",
    "    # the first half ([:,:half_width_at_scale]) of the image should be from the apple pyramid \n",
    "    # the second half ([:,half_width_at_scale:]) of the image should be from the orange pyramid\n",
    "    newPyr.append(np.hstack(\n",
    "        ( applePyr[i][:,:half_width_at_scale], orangePyr[i][:,half_width_at_scale:] )\n",
    "    ))\n",
    "\n",
    "# show apple, orange and new pyramids at all levels\n",
    "plt.figure(figsize=(20,6))\n",
    "for i in range(6):\n",
    "    # add 0.5 to the image if it is not the smallest level of the pyramid (i > 0)\n",
    "    # the smallest level of the pyramid (i == 0) is the original image, so we don't want to add 0.5\n",
    "    # use plt.subplot to show the images in a 3x6 grid\n",
    "\n",
    "    plt.subplot(3,6,1 + i),plt.imshow(newPyr[i] + (0.5 if i>0 else 0)),plt.title('New ' + str(i))\n",
    "    plt.subplot(3,6,7 + i),plt.imshow(applePyr[i] + (0.5 if i>0 else 0)),plt.title('Apple ' + str(i))\n",
    "    plt.subplot(3,6,13 + i),plt.imshow(orangePyr[i] + (0.5 if i>0 else 0)),plt.title('Orange ' + str(i))\n",
    "\n",
    "#TODO: your code here\n",
    "# reconstruct by adding GP to LP at each level.\n",
    "recon = newPyr[0]\n",
    "for i in range(1,6):\n",
    "    # upsample the reconstructed image using cv2.pyrUp\n",
    "    recon = cv2.pyrUp(recon)\n",
    "    # add the image at this level to the reconstructed image using cv2.add\n",
    "    recon = cv2.add(recon, newPyr[i])\n",
    "\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.subplot(131),plt.imshow(apple),plt.title('Apple')\n",
    "plt.subplot(132),plt.imshow(orange),plt.title('Orange')\n",
    "plt.subplot(133),plt.imshow(recon),plt.title('Reconstructed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corner Detection\n",
    "Implement the Harris corner detector.\n",
    "\n",
    "Use the functions `cv2.Sobel` and `cv2.Gaussian Blur` to implement the Harris corner criteria:\n",
    "$$\n",
    "Harris(\\hat{M}) = \\det(\\hat{M})-\\alpha\\mathrm{trace}(\\hat{M}) \\approx G(I_x^2)G(I_y^2)-G(I_xI_y)^2-\\alpha[G(I_x^2)+G(I_y^2)]^2\n",
    "$$\n",
    "Where $G$ is the Gaussian blur operator, and $I_x,I_y$ are image derivatives (Sobel) in $x$ and $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harris(im, k = int(3), alpha = 0.05):\n",
    "    # k is the kernel size for the Gaussian blur, alpha is the free parameter\n",
    "    # TODO: your code here\n",
    "    # compute the derivatives of the image in x and y directions using cv2.Sobel\n",
    "    # https://docs.opencv.org/4.x/d4/d86/group__imgproc__filter.html#gacea54f142e81b6758cb6f375ce782c8d\n",
    "    # to get the derivatives in x and y directions, use the dx = 1, dy = 0 and dx = 0, dy = 1 options\n",
    "    dx = cv2.Sobel(im, cv2.CV_64F, 1, 0)\n",
    "    dy = cv2.Sobel(im, cv2.CV_64F, 0, 1)\n",
    "\n",
    "    # compute the gaussian blur of the derivatives in x-x, x-y and y-y directions using cv2.GaussianBlur\n",
    "    # multiply the derivatives in x and y directions together to get the derivatives in x-y direction\n",
    "    # and then blur them using cv2.GaussianBlur with the kernel size k [a 2D kernel (k,k)]\n",
    "    dxx = cv2.GaussianBlur(dx**2, (k,k), 0)\n",
    "    dyy = cv2.GaussianBlur(dy**2, (k,k), 0)\n",
    "    dxy = cv2.GaussianBlur(dx*dy, (k,k), 0)\n",
    "\n",
    "    # compute the harris response function using the formula above and return it\n",
    "    return dxx*dyy - dxy**2 - alpha*((dxx+dyy)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of what this would look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = skimage.data.camera()\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.imshow(im, cmap='gray')\n",
    "har = harris(np.float32(im), 11, 0.05)\n",
    "plt.imshow(har, cmap='jet', alpha=0.75),plt.colorbar();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract the feature points from the Harris response image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the local maxima points in the image\n",
    "# the points are returned as a list of (x,y) tuples\n",
    "def findLocalMaxima(im, threshold=50):\n",
    "    #TODO: your code here\n",
    "    # find the points that are above the threshold by using the numpy argwhere function\n",
    "    # https://numpy.org/doc/stable/reference/generated/numpy.argwhere.html\n",
    "    # first convert the image to a boolean array by comparing the image to the threshold (im > threshold)\n",
    "    # the argwhere function returns the indices of the elements that are non-zero (i.e. True)\n",
    "    # the result is a list of (row, column) tuples\n",
    "    points = np.argwhere(im > threshold)\n",
    "\n",
    "    # convert the list of (row, column) tuples to a list of (x, y) tuples\n",
    "    points = [(p[1], p[0]) for p in points]\n",
    "\n",
    "    # find the points that are the local maxima\n",
    "    # by comparing the point to its 8 neighbors\n",
    "    maxima = []\n",
    "    for p in points:\n",
    "        # check that the point is not on the border of the image (because it has fewer than 8 neighbors)\n",
    "        # the first element of the point is the row and the second element is the column\n",
    "        # the shape of the image is accessed using the shape attribute of the array\n",
    "        # im.shape[0] is the number of rows and im.shape[1] is the number of columns\n",
    "        # so check that the point is not on the first or last row or column\n",
    "        # if the point is on the border, continue to the next point\n",
    "        \n",
    "        # e.g. if ... or ... or ... or ...:\n",
    "        #    continue\n",
    "        if p[0] == 0 or p[0] == im.shape[0] - 1 or p[1] == 0 or p[1] == im.shape[1] - 1:\n",
    "            continue\n",
    "\n",
    "        # check that the point is greater than or equal to all of its neighbors\n",
    "        # the neighbors are the 8 pixels around the point (including diagonals)\n",
    "        # the neighbors are accessed using array slicing with the syntax im[y1:y2, x1:x2]\n",
    "        # where y1:y2 is the range of rows and x1:x2 is the range of columns\n",
    "        # the range of rows and columns is inclusive on the lower bound and exclusive on the upper bound\n",
    "        # so im[p[1]-1:p[1]+2, p[0]-1:p[0]+2] is the 3x3 array of pixels around the point p (x, y)\n",
    "        # the np.all function returns true if all of the elements in the array are true\n",
    "        # https://numpy.org/doc/stable/reference/generated/numpy.all.html\n",
    "\n",
    "        # e.g. if np.all(...):\n",
    "            # if the point is greater than or equal to all of its neighbors\n",
    "            # then it is a local maximum and we add it to the list of maxima\n",
    "            maxima.append(p)\n",
    "\n",
    "        if np.all(im[p[1], p[0]] >= im[p[1]-1:p[1]+2, p[0]-1:p[0]+2]):\n",
    "            maxima.append(p)\n",
    "\n",
    "    return np.array(maxima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the local maxima points in the Harris response image har and plot them on top of the image\n",
    "harris_points = findLocalMaxima(har, 2e9)\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.imshow(im, cmap='gray')\n",
    "plt.scatter(harris_points[:,0], harris_points[:,1], c='r', s=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blob Detection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a blob detector with the Difference of Gaussians using the Gaussian pyramid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the difference of gaussians for the image in multiple scales\n",
    "# by using the cv2.pyrDown function to downsample the image by a factor of 2\n",
    "# and then subtracting the downsampled image from the original image\n",
    "# the result is a pyramid of images, where each image is the difference of gaussians\n",
    "# at a different scale.\n",
    "# then find the maximum value in the pyramid and find the blobs by thresholding\n",
    "# and applying simple non-maximum suppression.\n",
    "def showDoGPyramid(im_u8, levels=6):\n",
    "    im = np.float32(im_u8)\n",
    "    plt.figure(figsize=(20,10))\n",
    "\n",
    "    features = []\n",
    "\n",
    "    prev = im\n",
    "    for i in range(levels):\n",
    "        #TODO: your code here\n",
    "        # downsample the image by a factor of 2 by using the cv2.pyrDown function\n",
    "        im = cv2.pyrDown(prev)\n",
    "        # subtract the downsampled image from the original image by first using the cv2.pyrUp function\n",
    "        # to upsample the downsampled image to the original size and then subtracting the result\n",
    "        dogim = prev - cv2.pyrUp(im)\n",
    "        # store the current image as the previous image for the next iteration\n",
    "        prev = im\n",
    "\n",
    "        # plot the image by using the plt.imshow function with the cmap='gray' parameter\n",
    "        # in the subplot with 2 rows and 3 columns and the index i+1\n",
    "        \n",
    "        # plt.subplot(...) and plt.imshow(...) go here\n",
    "        plt.subplot(2, 3, i+1),plt.imshow(dogim, cmap='gray')\n",
    "\n",
    "        # find points that are local maxima in the image\n",
    "        # and are above the threshold (set the threshold to 60 - 10*i)\n",
    "        # use the findLocalMaxima function we defined above\n",
    "        points = findLocalMaxima(dogim, 60 - 10*i)\n",
    "        \n",
    "        # plot the points on the image\n",
    "        # the points are returned as a list of (x,y) tuples\n",
    "        # so we need to extract the x (e.g. p[0]) and y (e.g. p[1]) coordinates and plot them\n",
    "        # use the plt.plot function with the 'r.' parameter to plot the points as red dots\n",
    "        # and the markersize=5 parameter to set the size of the dots\n",
    "        \n",
    "        # plt.plot(...) goes here\n",
    "        plt.plot(points[:,0], points[:,1], 'r.', markersize=5)\n",
    "\n",
    "        # add the points to the list of features, with the level of the pyramid as the third element\n",
    "        # of the tuple\n",
    "        # scale the x and y coordinates by a factor of 2**i\n",
    "        # because the points are in the image at this level of the pyramid\n",
    "        \n",
    "        # features += [(..., ..., i) for p in points] goes here\n",
    "        features += [(p[0]*(2**i), p[1]*(2**i), i) for p in points]\n",
    "\n",
    "    return features\n",
    "\n",
    "found_features = showDoGPyramid(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the feature points on the image as circles with the level of the pyramid\n",
    "# as the radius of the circle\n",
    "def plotFeatures(im, features):\n",
    "    plt.figure(figsize=(20,10))\n",
    "    # plot the image\n",
    "    plt.imshow(im, cmap='gray')\n",
    "    # plot the circles\n",
    "    # the features are returned as a list of (x,y,level) tuples\n",
    "    for p in features:\n",
    "        # use the plt.gca function to get the current axes, https://matplotlib.org/api/_as_gen/matplotlib.pyplot.gca.html\n",
    "        # use the add_patch function to add a circle to the axes\n",
    "        # the circle is created using the plt.Circle function, https://matplotlib.org/api/_as_gen/matplotlib.patches.Circle.html\n",
    "        # the circle is centered at (p[0], p[1]) and has a radius of p[2]\n",
    "        # scale the radius by a power of 2 (2**p[2]) because the points are in the image at this level of the pyramid\n",
    "        \n",
    "        # e.g. plt.gca().add_patch(...) goes here\n",
    "        plt.gca().add_patch(plt.Circle((p[0], p[1]), 2**p[2], color='r', fill=False))\n",
    "\n",
    "# plot the features on the image\n",
    "plotFeatures(im, found_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orientation Estimation\n",
    "\n",
    "Now we have a set of feature points, let's try to estimate their orientation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The simplest possible orientation estimate is the average gradient within a region around the keypoint.\n",
    "def calculateOrientationForPoint(p, dx, dy):\n",
    "    #TODO: your code here\n",
    "    # get the x and y coordinates of the point\n",
    "    x = p[0]\n",
    "    y = p[1]\n",
    "    angles = []\n",
    "    # get the angle of the gradient vector for every pixel in a 5x5 window around the point\n",
    "    for i in range(-2, 3):\n",
    "        for j in range(-2, 3):\n",
    "            # calculate the angle of the gradient vector\n",
    "            # the angle of the gradient vector is the arctangent of the y gradient divided by the x gradient\n",
    "            # the arctangent function returns an angle in radians, so we need to convert\n",
    "            # the angle to degrees by multiplying by 180/pi\n",
    "            # get the gradients from dx and dy at the point (x+i, y+j), e.g. dx[y+j,x+i]\n",
    "            angle = np.arctan2(dy[y+j,x+i], dx[y+j,x+i]) * (180/np.pi)\n",
    "            # add the angle to the list of angles\n",
    "            angles.append(angle)\n",
    "\n",
    "    # return the average angle using the np.mean function\n",
    "    return np.mean(angles)\n",
    "\n",
    "# calculate the dominant orientation for each feature point\n",
    "def calculateDominantOrientation(im, features):\n",
    "    #TODO: your code here\n",
    "    # calculate the x and y gradients of the image\n",
    "    # the sobel function returns the x and y gradients\n",
    "    # the sobel function uses a 3x3 kernel, so the gradients are calculated at the center of each 3x3 kernel\n",
    "    # the gradients are calculated at the center of each 3x3 kernel, so the gradients are offset by 1 pixel\n",
    "    # from the edges of the image\n",
    "    # use the cv2.Sobel function to calculate the gradients\n",
    "    # the cv2.Sobel function takes the image, the data type, and the x and y derivatives\n",
    "    # https://docs.opencv.org/4.x/d4/d86/group__imgproc__filter.html#gacea54f142e81b6758cb6f375ce782c8d\n",
    "    # the data type is set to cv2.CV_64F to get a 64-bit float image\n",
    "    # the x and y derivatives are set to 1 to get the x and y gradients\n",
    "    # the cv2.Sobel function returns the x and y gradients as a tuple\n",
    "    # the x gradient is the first element of the tuple and the y gradient is the second element\n",
    "    dx, dy = cv2.Sobel(im, cv2.CV_64F, 1, 0), cv2.Sobel(im, cv2.CV_64F, 0, 1)\n",
    "\n",
    "    # calculate the dominant orientation for each feature point\n",
    "    orientations = []\n",
    "    for p in features:\n",
    "        # calculate the dominant orientation for the point\n",
    "        # the calculateOrientationForPoint function returns the angle of the gradient vector\n",
    "        # at the point p\n",
    "        # use the calculateOrientationForPoint function we defined above\n",
    "        angle = calculateOrientationForPoint(p, dx, dy)\n",
    "        # add the angle to the list of orientations\n",
    "        orientations.append(angle)\n",
    "\n",
    "    return orientations\n",
    "\n",
    "# calculate the dominant orientation for each feature point\n",
    "found_orientations = calculateDominantOrientation(im, found_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the orientations on the image\n",
    "def plotOrientations(im, features, orientations):\n",
    "    #TODO: your code here\n",
    "    # set the figure size to 10x10\n",
    "    # plt.figure(...) goes here\n",
    "    plt.figure(figsize=(10,10))\n",
    "\n",
    "    # plot the image\n",
    "    # plt.imshow(...) goes here\n",
    "    plt.imshow(im, cmap='gray')\n",
    "\n",
    "    # plot the circles\n",
    "    # the features are returned as a list of (x,y,level) tuples and the orientations are returned as a list of angles\n",
    "    for p, angle in zip(features, orientations):\n",
    "        # use the plt.gca function to get the current axes, https://matplotlib.org/api/_as_gen/matplotlib.pyplot.gca.html\n",
    "        # use the add_patch function to add a circle to the axes\n",
    "        # the circle is created using the plt.Circle function, https://matplotlib.org/api/_as_gen/matplotlib.patches.Circle.html\n",
    "        # the circle is centered at (p[0], p[1]) and has a radius of p[2]\n",
    "        # scale the radius by a power of 2 (2**p[2]) because the points are in the image at this level of the pyramid\n",
    "        \n",
    "        # plt.gca().add_patch(plt.Circle(...)) goes here\n",
    "        plt.gca().add_patch(plt.Circle((p[0], p[1]), 2**p[2], color='r', fill=False))\n",
    "\n",
    "        # plot the line from the center of the circle to the edge of the circle\n",
    "        # the angle of the line is the angle of the gradient vector at the point\n",
    "        # the angle is in degrees, so we need to convert it to radians by multiplying by pi/180\n",
    "        # the length of the line is the radius of the circle, e.g. 2**p[2]\n",
    "        # the x and y coordinates of the end of the line are the x and y coordinates of the center\n",
    "        # plus the length of the line times the cosine (for x) and sine (for y) of the angle\n",
    "        # e.g. [p[0], p[0] + 2**p[2] * np.cos(...)] for the x coordinates\n",
    "        plt.plot([p[0], p[0] + 2**p[2] * np.cos(angle * (np.pi/180))], [p[1], p[1] + 2**p[2] * np.sin(angle * (np.pi/180))], color='r')\n",
    "\n",
    "# plot the orientations on the image\n",
    "plotOrientations(im, found_features, found_orientations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: your code here\n",
    "\n",
    "# calculate the dominant orientation for each feature point in the harris_points list\n",
    "# using the calculateDominantOrientation function we defined above\n",
    "found_orientations = calculateDominantOrientation(im, harris_points)\n",
    "\n",
    "# plot the orientations for the harris_points on the image\n",
    "# but first add a mock level scale (e.g. 4) to the harris_points list, so the plotOrientations function works\n",
    "# the plotOrientations function expects a list of (x,y,level) tuples\n",
    "# but the harris_points list is a list of (x,y) tuples\n",
    "# augment the harris_points list with a mock level scale (e.g. 4) to make it a list of (x,y,level) tuples\n",
    "harris_points_with_level_scale = [(p[0], p[1], 4) for p in harris_points]\n",
    "\n",
    "# plot the orientations on the image\n",
    "plotOrientations(im, harris_points_with_level_scale, found_orientations)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a wrap!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
